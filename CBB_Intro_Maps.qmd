---
title: "ChiBlock Builder Data Exploration Report"
author: 
  - "**Great Cities Institute**"
  - "Tobin Greenwald and Kyle McFarren"
date: today
editor: 
  mode: visual
  markdown: 
    wrap: sentence
format:
  html:
    echo: false
    theme: sandstone
    toc: true
    toc_float: true
    number_sections: true
  pdf:
    number_sections: true
execute:
  eval: true
---

```{r setup, include=FALSE}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(kableExtra)
library(leaflet)
library(sf)
library(tigris)
library(forcats)
library(knitr)
library(tidyr)
library(tmap)
library(ggmap)
#library(leaflet.extras)
library(janitor)

options(dplyr.summarise.inform = FALSE)

#hiding these options here...
#code-fold: true
#    code-summary: "Show the code"

setwd("C:/GCI/CBB R")

knitr::opts_knit$set(root.dir = "C:/GCI/CBB R")
#knitr::opts_knit$set(root.dir = "C:/Users/kylem/MSCA/GCI/BlockBuilder Data/Intro Report")
data_clean <- read.csv("CBB_Data_Rebuild3.3.csv")

data_clean <- data_clean %>% select(1:37)

data_clean <- data_clean %>%
  mutate(Property.PIN = as.character(Property.PIN))

#data_clean <- read.csv("CBB_Data_Rebuild3.3.csv")
neighborhood_key <- read.csv("Neighborhood connection key.csv")
neighborhood_key <- neighborhood_key %>%
  dplyr::select(1, 2)

neighborhood_key <- neighborhood_key %>%
  rename(connection_time = `Length.of.time.that.applicant.has.had.connection.to.neighborhood`)

data_clean <- data_clean %>%
  left_join(neighborhood_key, by = c("connection" = "connection_time"))

#data_clean %>% filter(is.na(Translate.x))
#227 are NA

data_clean %>% filter(connection == "")
#267 are from a blank connection, those are ok

#data_clean %>% filter(connection != "") %>%
#  filter(is.na(Translate.x)) %>%
#  dplyr::select(connection)

#0 lines, all responses accounted for now

# data_clean <- data_clean %>%
#   rename(connection = connection, connection6 = Translate.x, applicant_ZIP = applicant_ZIP, hispanic = hispanic, LGBTQIA = LGBTQIA, age = age, income = income) %>%
#   dplyr::select(Record.ID, Name.Key, Person.Count, applicant_ZIP, Application.Status, Application.Type, Property.PIN, Property.Applications, Date.Submitted, Property.Type.of.Land, Property.Address, connection2, Applicant.Race, hispanic, Gender.Identity, LGBTQIA,  everything())

# Clean up the entity types in the data
data_clean <- data_clean %>%
  mutate(Purchasing.Entity.Type = case_when(
    Purchasing.Entity.Type %in% c("For-Profit Business Corporation", "For Profit Busines Corporation", "For-profit corporation") ~ "For-Profit Organization",
    Purchasing.Entity.Type == "Individual" ~ "Sole Proprietor/Individual",
    is.na(Purchasing.Entity.Type) | Purchasing.Entity.Type == "" ~ "Not Provided",
    TRUE ~ Purchasing.Entity.Type  # Leave other types as is
  ))

# Clean up any invalid UTF-8 characters in Name.Key and Purchasing.Entity.Type
data_clean <- data_clean %>%
  mutate(Name.Key = iconv(Name.Key, from = "UTF-8", to = "ASCII", sub = ""),
         Purchasing.Entity.Type = iconv(Purchasing.Entity.Type, from = "UTF-8", to = "ASCII", sub = ""))

data_clean %>%
  count(Application.Status)

data_clean$Application.Status2 <- data_clean$Application.Status  # Step 1: Create the field

# Step 2: Recode "Withdrawn" or "Declined" into "Declined & Withdrawn"
data_clean$Application.Status2 <- ifelse(data_clean$Application.Status %in% c("Withdrawn", "Declined"),
                                         "Declined & Withdrawn",
                                         data_clean$Application.Status2)

# Replace blanks/NA in Purchasing.Entity.Type with "Not Provided"
data_clean <- data_clean %>%
  mutate(Purchasing.Entity.Type = case_when(
    Purchasing.Entity.Type %in% c("For-Profit Business Corporation", "For Profit Busines Corporation", "For-profit corporation") ~ "For-Profit Organization",
    Purchasing.Entity.Type == "Individual" ~ "Sole Proprietor/Individual",
    is.na(Purchasing.Entity.Type) | Purchasing.Entity.Type == "" ~ "Not Provided", # Include previous cleaning step
    TRUE ~ Purchasing.Entity.Type  # Leave other entries unchanged
  ))

#take changes made further down and put them all here in the intro/setup section
person_lot_count <- data_clean %>%
  group_by(Person.Count) %>%
  distinct(Name.Key) %>%
  summarise(Count_of_People = n_distinct(Name.Key),           # Count distinct people by Name.Key
            Lots_Accounted_For = sum(Person.Count)) %>%  # Calculate total lots
  arrange(Person.Count)

# Create a new variable for the count of lots applied for each Name & Entity Type combo
data_clean <- data_clean %>%
  group_by(Name.Key, Purchasing.Entity.Type) %>%
  mutate(Lot_Application_Count = n()) %>%  # New variable for the count of lots per Person & Entity Type combo
  ungroup()

# Add a column indicating if the entity applied for 1 lot or more than 1 lot based on this new variable
data_clean <- data_clean %>%
  mutate(Lot_Application_Group = case_when(
    Lot_Application_Count == 1 ~ "1 lot",
    Lot_Application_Count > 1 ~ ">1 lot"
  ))

# Convert Date.Submitted to Date format
data_clean <- data_clean %>%
  mutate(Date.Submitted = as.Date(Date.Submitted, format = "%m/%d/%Y"))


# Create a new column for "Sole Proprietor/Individual" or "All Others"
data_clean <- data_clean %>%
  mutate(Entity_Type_Group = case_when(
    Purchasing.Entity.Type == "Sole Proprietor/Individual" ~ "Sole Proprietor/Individual",
    TRUE ~ "All Others"
  ))

# Filter the data for each window and create a categorical variable for each window
data_clean <- data_clean %>%
  mutate(Application_Window = case_when(
    Date.Submitted >= as.Date("2022-11-01") & Date.Submitted <= as.Date("2023-05-31") ~ "Window 1, Nov '22 - May '23",
    Date.Submitted >= as.Date("2023-11-01") & Date.Submitted <= as.Date("2024-01-31") ~ "Window 2, Nov '23 - Jan '24",
    Date.Submitted >= as.Date("2024-03-01") & Date.Submitted <= as.Date("2024-07-31") ~ "Window 3, March '24 - July '24",
    TRUE ~ NA_character_  # Exclude other dates
  ))

#deomgraphic data, really only applies to individuals but filling in for everyone here

data_clean <- data_clean %>%
  mutate(Applicant.Race = ifelse(is.na(Applicant.Race) | Applicant.Race == "", "Not Provided", Applicant.Race), 
         Gender.Identity = ifelse(is.na(Gender.Identity) | Gender.Identity == "", "Not Provided", Gender.Identity), 
         hispanic = ifelse(is.na(hispanic) | hispanic == "", "Not Provided", hispanic), 
         hispanic = ifelse(hispanic == "Not Hispanic or Latino/ Latina/ Latinx", 
                           "Not Hispanic or Latino/Latina/Latinx", hispanic), 
         LGBTQIA = ifelse(is.na(LGBTQIA) | LGBTQIA == "", "Not Provided", LGBTQIA), 
         age = case_when(age == "18-24" ~ "18 - 24", age == "25-34" ~ "25 - 34", age == "35-44" ~ "35 - 44",
          age == "45-54" ~ "45 - 54", TRUE ~ age),  # Leave all other age values unchanged
         age = ifelse(is.na(age) | age == "", "Not Provided", age), 
         income = as.character(income),   # Convert to character
         income = str_trim(income),       # Trim whitespace
         income = ifelse(income %in% c("NA", "") | is.na(income), "Not Provided", income), # Replace "NA" text, blanks, actual NAs
         connection2 = ifelse(connection2 == "10-20 years", "11-20 years", connection2), 
         connection2 = ifelse(is.na(connection2) | connection2 == "", "Not Provided", connection2)
         )

# Extract Property ZIP Code to capture 5 digits before ', USA'
#data_clean$Property_ZipCode <- str_extract(data_clean$address, "\\d{5}(?=, usa)")

# Remove blanks in Application.Type (will clean this later w/ Urban Agriculture lots, etc)
#data_clean <- data_clean
#  mutate(Application.Type = ifelse(is.na(Application.Type) | Application.Type == "", "Not Listed", Application.Type))

data_clean <- data_clean %>%
  mutate(Application.Type = ifelse(is.na(Application.Type) | Application.Type == "", "Not Provided", Application.Type))

#write.csv(data_clean, "CBB_Data_Rebuild2.27.csv", row.names = FALSE)

```


# Application Status by community Area

```{r}
data_clean_comm_area <- data_clean %>% 
  filter(!is.na(lon)) 

# make dataframe into spatial feature 
comm_area_apps_sf <- st_as_sf(x= data_clean_comm_area, coords = c("lon", "lat"), crs = 4326)

comm_area_boundaries <- read_sf("geo_export_a446ed1e-4dd2-4beb-b7b6-6fb916b4bdde.shp")
comm_area_boundaries <- st_transform(comm_area_boundaries, crs = 3435)

#change the application layer CRS to equal 3435
comm_area_apps_sf <- st_transform(comm_area_apps_sf, crs = st_crs(comm_area_boundaries))

# Join polygon features to points
comm_area_data <- st_join(comm_area_apps_sf, comm_area_boundaries, join = st_intersects)

comm_area_table <- comm_area_data %>%
  group_by(community) %>%
  summarise(Unique_Property_PINs = n_distinct(Property.PIN)) %>%
  arrange(desc(Unique_Property_PINs))

comm_area_data$Application.Status2 <- comm_area_data$Application.Status  # Step 1: Create the field

comm_area_data$Application.Status2 <- ifelse(comm_area_data$Application.Status %in% c("Withdrawn", "Declined"),
                                         "Declined & Withdrawn",
                                         comm_area_data$Application.Status2)


comm_area_data <- st_drop_geometry(comm_area_data)

comm_area_status_count_table <- comm_area_data %>%
  group_by(community, Application.Status2) %>%
  summarise(Count = n()) %>%
  ungroup()

comm_area_status_pivot_count_table <- comm_area_status_count_table %>%
  dplyr::select(community, Application.Status2, Count) %>%
  pivot_wider(names_from = Application.Status2, values_from = Count, values_fill = 0)

comm_area_status_pivot_count_table <- comm_area_status_pivot_count_table %>%
  dplyr::select(community, "Accepted", "In-Progress", "Declined & Withdrawn")


comm_area_status_percent_table <- comm_area_data %>%
  group_by(community, Application.Status2) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = Count / sum(Count) * 100) %>%
  ungroup()

total_count_by_comm_area <- comm_area_status_percent_table %>%
  group_by(community) %>%
  summarize(Total_Count = sum(Count, na.rm = TRUE))

comm_area_status_pivot_table <- comm_area_status_percent_table %>%
  dplyr::select(community, Application.Status2, Percentage) %>%
  pivot_wider(names_from = Application.Status2, values_from = Percentage, values_fill = 0) %>%
  left_join(total_count_by_comm_area, by = "community")

comm_area_status_pivot_table <- comm_area_status_pivot_table %>%
  dplyr::select(community, Total_Count, "Accepted", "In-Progress", "Declined & Withdrawn")

comm_area_status_pivot_table <- comm_area_status_pivot_table %>%
  mutate(across(where(is.numeric), ~ round(.x, 1)))

######## CREATE DEMAND SCORE 

#ensure universe is clean
# filtered_data <- data_clean %>%
#   filter(!is.na(Property_ZipCode) & Property_ZipCode != 0)

# Get unique Property.PIN values
unique_lots_commarea <- comm_area_data %>%
  distinct(Property.PIN, community)

# Count unique lots by Community Area
commarea_lot_counts <- unique_lots_commarea %>%
  group_by(community) %>%
  summarise(Unique.Lots.by.Commarea = n(), .groups = "drop")

# Check the total record count
nrow(unique_lots_commarea)  # Should returned 1100 records

# Count unique applications by Community Area
commarea_app_counts <- comm_area_data %>%
  filter(!is.na(Property_ZipCode) & Property_ZipCode != 0) %>%
  group_by(community) %>%
  summarise(Property.Applications.by.Commarea = n(), .groups = "drop")

# Join the two values into one dataset
commarea_summary <- commarea_lot_counts %>%
  full_join(commarea_app_counts, by = c("community" = "community")) 

# Calculate "Demand" 
commarea_summary <- commarea_summary %>%
  mutate(Commarea.Demand.Score = Property.Applications.by.Commarea / Unique.Lots.by.Commarea)

commarea_summary <- commarea_summary %>%
  mutate(across(where(is.numeric), ~ round(.x, 1))) %>%
  select(community,Commarea.Demand.Score)

######## JOIN DEMAND SCORE TO TABLE

comm_area_status_pivot_table <- left_join(comm_area_status_pivot_table, commarea_summary, by = "community")

#Reorder the columns 
comm_area_status_pivot_table <- comm_area_status_pivot_table %>%
  dplyr::select(community, Total_Count, Commarea.Demand.Score, "Accepted", "In-Progress", "Declined & Withdrawn")

######## CREATE TABLE

comm_area_status_pivot_table %>%
  arrange(desc(Total_Count)) %>%
  filter(Total_Count >= 10) %>%
  kable(col.names = c("Community Area", "Count of Applications", "Demand Score", "Accepted (%)", "In-Progress (%)", "Declined & Withdrawn (%)"),
        caption = "Percent of Application Status by Community Area")

```



# Maps


```{r}
data_clean <- data_clean %>% rename(applicant_ZIP = Applicant.ZIP.Code)

# take all data and deduplicate based on name and applicant zip code.
zip_data <- data_clean %>%
  distinct(Name.Key, applicant_ZIP) %>%
  group_by(applicant_ZIP) %>%
  summarise(Count = n()) %>%
  filter(!is.na(applicant_ZIP) & applicant_ZIP != "")  # Filter out missing ZIPs


```

Exploring the home zip code of the applicants, there are 1,300 name:applicant zip combinations.

23 applicants provided a home ZIP Code from outside of Chicago.

```{r, eval=FALSE, warning=FALSE}
# Download ZIP code shapefiles for Cook County (includes Chicago)
zip_shapes <- zctas(cb = FALSE, year = 2010, state = "IL")

# Transform to correct CRS if necessary
zip_shapes <- st_transform(zip_shapes, crs = 3435)
st_write(zip_shapes, "zip_shapes.shp")
```

```{r}
zip_shapes <- read_sf("zip_shapes.shp")
# Step 1: Identify and summarize ZIPs outside of Illinois by performing an anti_join
outside_il_data <- zip_data %>%
  anti_join(zip_shapes, by = c("applicant_ZIP" = "ZCTA5CE10")) %>%
  summarise(Outside_IL_Count = sum(Count))

# Step 2: Filter out applicants with ZIPs outside Illinois
zip_data_il <- zip_data %>%
  semi_join(zip_shapes, by = c("applicant_ZIP" = "ZCTA5CE10"))

zip_shapes_merged <- zip_shapes %>%
  left_join(zip_data_il, by = c("ZCTA5CE10" = "applicant_ZIP"))  # Adjust column names if needed

# Fill NAs in Count with 0 (for ZIPs with no applicants)
zip_shapes_merged$Count[is.na(zip_shapes_merged$Count)] <- 0

```

# Figure 10: Lot Count by Zip Code as of February 11, 2025

```{r}
zip_shapes_chi <- read_sf("zip_shapes.shp")

#read in city boundary
city_boundary <- read_sf("city_boundary.shp")
city_boundary <- st_transform(city_boundary, crs = 3435)

# 
zip_data_prop <- data_clean %>%
  # Create unique combinations of property PINs and zip codes, so that properties only appear once
  distinct(Property.PIN, Property_ZipCode) %>%
  group_by(Property_ZipCode) %>%
  summarise(Count = n()) %>%
  filter(!is.na(Property_ZipCode) & Property_ZipCode != "")  # Filter out missing ZIPs
#there are 1,101 lots with valid ZIP codes

view_sum <- zip_data_prop %>%
  summarise(total = sum(Count, na.rm = TRUE))

# Convert Property_ZIPCode to character
zip_data_prop <- zip_data_prop %>%
  mutate(Property_ZipCode = as.character(Property_ZipCode))

# Filter out applicants with ZIPs outside Illinois
zip_data_il <- zip_data_prop %>%
  semi_join(zip_shapes_chi, by = c("Property_ZipCode" = "ZCTA5CE10"))
#still 1,126 lots with valid ZIP codes

zip_shapes_merged_chi <- zip_shapes_chi %>%
  left_join(zip_data_il, by = c("ZCTA5CE10" = "Property_ZipCode"))  # Adjust column names if needed

# Fill NAs in Count with 0 (for ZIPs with no applicants)
zip_shapes_merged_chi$Count[is.na(zip_shapes_merged_chi$Count)] <- 0

zip_shapes_merged_chi <- st_transform(zip_shapes_merged_chi, crs = st_crs(city_boundary))

#Spatial join
zips_chi_join <- zip_shapes_merged_chi[st_intersects(zip_shapes_merged_chi, city_boundary, sparse = FALSE), ]

zips_chi_join <- zips_chi_join %>%
  mutate(Count = ifelse(is.na(Count), 0, Count))

zips_chi_join <- zips_chi_join %>%
  mutate(Count_Label = as.character(Count))  # Ensure all counts, including 0, are numeric as characters

# zips_chi_join <- zips_chi_join %>%
#   mutate(Count_Label = ifelse(Count == 0, NA, as.character(Count)))  # Set 0 values to NA for labels

zips_chi_join <- st_intersection(zips_chi_join, city_boundary)

tm_shape(zips_chi_join) +
  tm_polygons(col = "Count", 
              title = "Lot Count",
              palette = "Greens",
              breaks = c(0, 1, 10, 37, 69, 133, max(zips_chi_join$Count, na.rm = TRUE)), 
              labels = c("No lots applied for", "1-9", "10-36", "37-68", "69-132", "133-217"),
              NA.hide = TRUE) +  # Hide NA values from the legend
  tm_layout(legend.position = c("left", "bottom"), legend.outside = FALSE, frame = FALSE) +
  tm_text("Count_Label", size = 0.5, col = "black", remove.overlap = TRUE) +  
  tm_title("Figure 10. Lot Count by Zip Code as of February 11, 2025")

# tm_shape(zips_chi_join) +
#   tm_polygons(fill = "Count", 
#               fill.scale = tm_scale_intervals(n = 5, style = "jenks", values = "greens")) +
#   tm_layout(legend.outside = TRUE, frame = FALSE) +
#   tm_text("Count", size = 0.5, col = "black", remove.overlap = TRUE) +
#   tm_title("Lot Count by Zip Code")



# # Drop geometry
# zips_chi_join <- st_drop_geometry(zips_chi_join)
# 
# # Export to CSV
# write.csv(zips_chi_join, "Figure_10_March4.csv", row.names = FALSE)

```

# Figure 11: Count of Applicants by Residential ZIP Code as of February 11, 2025

```{r, message=FALSE, warning=FALSE}

# APPLICANT COUNT BY ZIP CODE

#remove zip codes with applicant counts of zero
# zip_shapes_merged_cleaned <- zip_shapes_merged %>%
#  filter(Count > 0)

#read in city boundary
city_boundary <- read_sf("city_boundary.shp")
city_boundary <- st_transform(city_boundary, crs = 3435)

#Align CRCS between the two files to join
zip_shapes_merged <- st_transform(zip_shapes_merged, crs = st_crs(city_boundary))
# 1,384 records in zip_shapes_merged 

# filter out zips that are mostly outside Chicago 
#zip_shapes_merged <- zip_shapes_merged %>%
 # filter()

#Spatial join
zips_chi_app <- zip_shapes_merged[st_intersects(zip_shapes_merged, city_boundary, sparse = FALSE), ]

zips_chi_app <- zips_chi_app %>%
  mutate(Count = replace_na(Count, 0))

zips_chi_app <- st_intersection(zips_chi_app, city_boundary)

tm_shape(zips_chi_app) +
  tm_polygons(fill = "Count", 
              fill.scale = tm_scale_intervals(n = 5, style = "jenks", values = "brewer.blues")) +
  tm_layout(legend.outside = TRUE, frame = FALSE) +
  tm_title("Applicant Count by Zip Code")


```

# Figure 12 Percent of applicants from within the same ZIP code

```{r}

# For zip codes that are the same for applicant and property, summarise applications (rows) by zip code and count the number of times that each zip appears in a new column called "local_count"
matched_zips <- data_clean %>%
  filter(applicant_ZIP == Property_ZipCode) %>% # filters rows where applicant_ZIP matches Property_ZipCode, keeping only records where the ZIP codes are the same.
  distinct(Name.Key, .keep_all = TRUE) %>% # Removes duplicate rows based on the Name.Key column.
  group_by(applicant_ZIP) %>%
  summarise(local_count = n()) # Counts the number of rows in each group (i.e., the number of unique Name.Key entries per applicant_ZIP).

# For ALL zip codes, summarise applicants by zip code of the property they applied to and count the number of applicants in a new column called "total_count"
total_zips <- data_clean %>%
  distinct(Name.Key, .keep_all = TRUE) %>%
  group_by(Property_ZipCode) %>%
  summarise(total_count = n())

total_zips <- total_zips %>%
  mutate(Property_ZipCode = as.character(Property_ZipCode))

joined_zips <- inner_join(total_zips,matched_zips, by = c("Property_ZipCode" = "applicant_ZIP"))

# Calculate the percentage of local applicants
joined_zips <- joined_zips %>%
  mutate(percent_local = (local_count / total_count) * 100)

percent_local_zips <- left_join(zips_chi_join, joined_zips, by = c("ZCTA5CE10" = "Property_ZipCode"))

percent_local_zips <- percent_local_zips %>%
  mutate(percent_local = replace_na(percent_local, 0))

percent_local_zips <- st_intersection(percent_local_zips, city_boundary)


tm_shape(percent_local_zips) +
  tm_polygons(fill = "percent_local", 
              fill.scale = tm_scale_intervals(n = 5, style = "jenks", values = "brewer.blues")) +
  tm_layout(legend.outside = TRUE, frame = FALSE) +
  tm_title("Percent of Applicants from within same ZIP Code")


```

# Figure 13: Percent of applications from within the same ZIP code for Individuals/Sole Proprietors only

```{r}

data_clean_individual <- data_clean %>%
  filter(Entity_Type_Group == "Sole Proprietor/Individual")

matched_zips <- data_clean %>%
  filter(applicant_ZIP == Property_ZipCode) %>% # filters rows where applicant_ZIP matches Property_ZipCode, keeping only records where the ZIP codes are the same.
  distinct(Name.Key, .keep_all = TRUE) %>% # Removes duplicate rows based on the Name.Key column.
  group_by(applicant_ZIP) %>%
  summarise(local_count = n()) # Counts the number of rows in each group (i.e., the number of unique Name.Key entries per applicant_ZIP).

# For ALL zip codes, summarise applicants by zip code of the property they applied to and count the number of applicants in a new column called "total_count"
total_zips <- data_clean %>%
  distinct(Name.Key, .keep_all = TRUE) %>%
  group_by(Property_ZipCode) %>%
  summarise(total_count = n())

total_zips <- total_zips %>%
  mutate(Property_ZipCode = as.character(Property_ZipCode))

joined_zips <- inner_join(total_zips,matched_zips, by = c("Property_ZipCode" = "applicant_ZIP"))

# Calculate the percentage of local applicants
joined_zips <- joined_zips %>%
  mutate(percent_local = (local_count / total_count) * 100)

percent_local_zips <- left_join(zips_chi_join, joined_zips, by = c("ZCTA5CE10" = "Property_ZipCode"))

percent_local_zips <- percent_local_zips %>%
  mutate(percent_local = replace_na(percent_local, 0))

percent_local_zips <- st_intersection(percent_local_zips, city_boundary)

tm_shape(percent_local_zips) +
  tm_polygons(fill = "percent_local", 
              fill.scale = tm_scale_intervals(n = 5, style = "jenks", values = "brewer.blues")) +
  tm_layout(legend.outside = TRUE, frame = FALSE) +
  tm_title("Percent of Applicants from within same ZIP Code for Sole Proprietors/Individuals")


```

All of the pale zips have low single digit applicant counts.
The darker the blue, the higher the concentration of applicant "home zip codes".

Property ZIP vs Applicant ZIP

```{r}

# Calculate the number of ZIP matches
match_count <- data_clean %>%
  filter(applicant_ZIP == Property_ZipCode) %>%
  nrow()

# Total number of rows
total_count <- nrow(data_clean)

# Calculate the percentage of matching rows
match_percentage <- (match_count / total_count) * 100

```

# Figure 16: Residential ZIP Code Locations of Applicants for Lots in 60612 Zip Code as of February 11, 2025

```{r}

shapefile_path <- "C:/GCI/CBB R/CBB_Initial_Report/city_boundary.shp"
chicago_boundary <- st_read(shapefile_path)

# Calculate the number of non-ZIP matches
diff_zips <- data_clean %>%
  filter(applicant_ZIP != Property_ZipCode)
# 1,051 records found with non-matching zip-codes

#Break diff zips into two different dataframes
applicant_zips <- diff_zips
property_zips <- diff_zips

# Join zip shapefile to applicant_zips
applicat_zips_sf <- zip_shapes %>%
  inner_join(applicant_zips, by = c("ZCTA5CE10" = "applicant_ZIP"))
# 1,009 applicant with ZIP codes in IL

# Convert Property_ZIPCode to character
property_zips <- property_zips %>%
  mutate(Property_ZipCode = as.character(Property_ZipCode))

property_points_sf <- zip_shapes %>%
  inner_join(property_zips, by = c("ZCTA5CE10" = "Property_ZipCode"))

# Change zip polygons to centroid points
applicant_zips_points_sf <- st_centroid(applicat_zips_sf)
# applicant_zips_points_sf has 1,009 records
property_zips_points_sf <- st_centroid(property_points_sf)
# property_zips_points_sf has 828 records


# Transform applicant points to match Chicago CRS
applicant_zips_points_sf <- st_transform(applicant_zips_points_sf, st_crs(chicago_boundary))
property_zips_points_sf <- st_transform(property_zips_points_sf, st_crs(chicago_boundary))

# Clip points so they are limited to cook county
applicant_zips_points_sf <- st_intersection(applicant_zips_points_sf, chicago_boundary)
property_zips_points_sf <- st_intersection(property_zips_points_sf, chicago_boundary)

# Extract coordinates first from applicant points
applicant_zips_points_sf <- applicant_zips_points_sf %>%
  mutate(
    INTPTLON10 = st_coordinates(.)[,1], 
    INTPTLAT10 = st_coordinates(.)[,2]
  ) %>%
  st_drop_geometry()  # Drop geometry before joining

# Extract coordinates first from property points & shift west
property_zips_points_sf <- property_zips_points_sf %>%
  mutate(
    INTPTLON10 = st_coordinates(.)[,1] - 0.0068,  # Shift west
    INTPTLAT10 = st_coordinates(.)[,2]
  ) %>%
  st_drop_geometry()  # Drop geometry before joining

# Ensure property_zips_points_sf column names are unique BEFORE join
property_zips_points_sf <- property_zips_points_sf %>%
  rename(
    INTPTLON10_prop = INTPTLON10,  # Rename longitude for property zips
    INTPTLAT10_prop = INTPTLAT10   # Rename latitude for property zips
  )

# Perform inner join
apptoprop_df <- inner_join(
  applicant_zips_points_sf, property_zips_points_sf, 
  by = "Record.ID"
)

# Filter dataframe to only applications for properties with more than 5 applications
apptoprop_df <- apptoprop_df %>%
  filter(ZCTA5CE10.y == 60612)


line_geometries <- st_sfc(
  lapply(1:nrow(apptoprop_df), function(i) {
    st_linestring(rbind(
      c(apptoprop_df$INTPTLON10[i], apptoprop_df$INTPTLAT10[i]),  # Start point
      c(apptoprop_df$INTPTLON10_prop[i], apptoprop_df$INTPTLAT10_prop[i]) # End point
    ))
  }),
  crs = 4269  # Ensure correct CRS (change if needed)
)

# Convert the dataframe into an sf object with the geometry column
apptoprop_sf <- st_sf(apptoprop_df, geometry = line_geometries)

applicant_zips_points_sf <- applicant_zips_points_sf %>%
   filter(Property_ZipCode == 60612)

property_zips_points_sf <- property_zips_points_sf %>%
   filter(ZCTA5CE10 == 60612)

external_zips <- property_zips_points_sf %>%
  group_by(applicant_ZIP) %>%
  summarise(Count = n())


# Ensure applicant points are sf objects
applicant_zips_points_sf <- st_as_sf(applicant_zips_points_sf, 
                                     coords = c("INTPTLON10", "INTPTLAT10"), 
                                     crs = 4269)  # Adjust CRS as needed

# Ensure property points are sf objects
property_zips_points_sf <- st_as_sf(property_zips_points_sf, 
                               coords = c("INTPTLON10_prop", "INTPTLAT10_prop"), 
                               crs = 4269)

apptoprop_sf <- st_transform(apptoprop_sf, crs = 4326)
applicant_zips_points_sf <- st_transform(applicant_zips_points_sf, crs = 4326)
property_zips_points_sf <- st_transform(property_zips_points_sf, crs = 4326)

# Create the leaflet map
leaflet() %>%
  addProviderTiles(providers$CartoDB.Positron) %>%  # Minimal basemap

  # Add ZIP Code Outlines (Dark Grey)
  addPolygons(data = zip_shapes, 
              color = "darkgrey",  # Outline color
              weight = 1,  # Line thickness
              fill = FALSE,  # No fill
              opacity = 1) %>%
  
  
  # Add Lines (Black)
  addPolylines(data = apptoprop_sf, color = "black", weight = 1) %>%
  
  # Add Start Points (Applicant ZIPs) in Blue
  addCircleMarkers(data = applicant_zips_points_sf, 
                   color = "blue", radius = 2) %>%
  
  # Add End Points (Property ZIPs) in Red
  addCircleMarkers(data = property_zips_points_sf, 
                   color = "red", radius = 2) %>%

# Set View to Chicago
  setView(lng = -87.6298, lat = 41.8781, zoom = 11)  # Chicago's coordinates




```

# Exporting Shapefiles for Figure 16

```{r}

fix_field_names <- function(names_vec, max_length = 9) {
  new_names <- character(length(names_vec))
  used_names <- character(0)
  for (i in seq_along(names_vec)) {
    # Start with a truncated base name
    base <- substr(names_vec[i], 1, max_length)
    new_name <- base
    suffix <- 1
    # Ensure the new name is unique
    while(new_name %in% used_names) {
      # Reserve room for underscore and suffix
      avail <- max_length - nchar(as.character(suffix)) - 1 
      new_name <- paste0(substr(base, 1, avail), "_", suffix)
      suffix <- suffix + 1
    }
    new_names[i] <- new_name
    used_names <- c(used_names, new_name)
  }
  new_names
}

# Fix field names for each sf object
names(applicant_zips_points_sf) <- fix_field_names(names(applicant_zips_points_sf), max_length = 9)
names(property_zips_points_sf)  <- fix_field_names(names(property_zips_points_sf), max_length = 9)

# (Optional) Check that the names are unique
if(any(duplicated(names(applicant_zips_points_sf)))) {
  stop("There are still duplicates in applicant_zips_points_sf!")
}
if(any(duplicated(names(property_zips_points_sf)))) {
  stop("There are still duplicates in property_zips_points_sf!")
}

# Write to shapefiles
# st_write(applicant_zips_points_sf, "Figure_16_Applicant_Dots.shp", driver = "ESRI Shapefile")
# st_write(property_zips_points_sf,  "Figure_16_Property_Dots.shp", driver = "ESRI Shapefile")

```




# Percent of applications from within the same ZIP code for non-individual entities

```{r}

data_clean_group <- data_clean %>%
  filter(Entity_Type_Group == "All Others")

# For zip codes that are the same for applicant and property, summarise applications (rows) by zip code and count the number of times that each zip appears in a new column called "local_count"
matched_zips <- data_clean_group %>%
  filter(applicant_ZIP == Property_ZipCode) %>%
  group_by(applicant_ZIP) %>%
  summarise(local_count = n())

# For ALL zip codes, summarise applications (rows) by zip code and count the number of times that each zip appears in a new column called "time_count"
total_zips <- data_clean %>%
  filter(applicant_ZIP == Property_ZipCode) %>%
  group_by(applicant_ZIP) %>%
  summarise(total_count = n())

joined_zips <- inner_join(total_zips,matched_zips, by = "applicant_ZIP")

# Calculate the percentage of local applicants
joined_zips <- joined_zips %>%
  mutate(percent_local = (local_count / total_count) * 100)

percent_local_zips <- left_join(zips_chi_join, joined_zips, by = c("ZCTA5CE10" = "applicant_ZIP"))

percent_local_zips <- percent_local_zips %>%
  mutate(percent_local = replace_na(percent_local, 0))

tm_shape(percent_local_zips) +
  tm_polygons(fill = "percent_local", 
              fill.scale = tm_scale_intervals(n = 5, style = "equal", values = "brewer.blues")) +
  tm_layout(legend.outside = TRUE, frame = FALSE) +
  tm_title("Percent of Applications from within ZIP Code for non-individual entities")


```

# Percent of applications going to different ZIP Codes

```{r}

zip_shapes 

# For zip codes that are different for applicant and property, summarise applications (rows) by zip code and count the number of times that each zip # # appears in a new column called "non_local_count"
non_matched_zips <- data_clean %>%
  filter(applicant_ZIP != Property_ZipCode) %>%
  group_by(applicant_ZIP) %>%
  summarise(non_local_count = n())

# For ALL zip codes, summarise applications (rows) by zip code and count the number of times that each zip appears in a new column called "total_count"
total_zips <- data_clean %>%
  group_by(applicant_ZIP) %>%
  summarise(total_count = n())

joined_zips <- inner_join(total_zips,non_matched_zips, by = "applicant_ZIP")

# Calculate the percentage of non-local applicants
joined_zips <- joined_zips %>%
  mutate(percent_non_local = (non_local_count / total_count) * 100)

percent_non_local_zips <- left_join(zips_chi_join, joined_zips, by = c("ZCTA5CE10" = "applicant_ZIP"))

percent_non_local_zips <- percent_non_local_zips %>%
  mutate(percent_non_local = replace_na(percent_non_local, 0))

tm_shape(percent_non_local_zips) +
  tm_polygons(fill = "percent_non_local", 
              fill.scale = tm_scale_intervals(n = 5, style = "jenks", values = "brewer.blues")) +
  tm_layout(legend.outside = TRUE, frame = FALSE) +
  tm_title("Percent of Applications to properties in different ZIP Code")

```

# Percent of applications going to different ZIP Codes

```{r}

zip_shapes 

# For zip codes that are different for applicant and property, summarise applications (rows) by zip code and count the number of times that each zip # # appears in a new column called "non_local_count"
non_matched_zips <- data_clean %>%
  filter(applicant_ZIP != Property_ZipCode) %>%
  group_by(applicant_ZIP) %>%
  summarise(non_local_count = n())

# For ALL zip codes, summarise applications (rows) by zip code and count the number of times that each zip appears in a new column called "total_count"
total_zips <- data_clean %>%
  group_by(applicant_ZIP) %>%
  summarise(total_count = n())

invest_zips <- data_clean %>%
  filter(Property_ZipCode == "60612")

joined_zips <- inner_join(total_zips,non_matched_zips, by = "applicant_ZIP")

# Calculate the percentage of non-local applicants
joined_zips <- joined_zips %>%
  mutate(percent_non_local = (non_local_count / total_count) * 100)

percent_non_local_zips <- left_join(zips_chi_join, joined_zips, by = c("ZCTA5CE10" = "applicant_ZIP"))

percent_non_local_zips <- percent_non_local_zips %>%
  mutate(non_local_count = replace_na(non_local_count, 0))

tm_shape(percent_non_local_zips) +
  tm_polygons(fill = "non_local_count", 
              fill.scale = tm_scale_intervals(n = 5, style = "jenks", values = "brewer.blues")) +
  tm_layout(legend.outside = TRUE, frame = FALSE) +
  tm_title("Percent of Applications from outside property ZIP Code")

```

# Count of applications coming from outside ZIP Codes

```{r}

zip_shapes 

# For zip codes that are different for applicant and property, summarise applications (rows) by zip code and count the number of times that each zip # # appears in a new column called "non_local_count"
non_matched_zips <- data_clean %>%
  filter(applicant_ZIP != Property_ZipCode) %>%
  group_by(Property_ZipCode) %>%
  summarise(outside_app_count = n())

# Convert Property_ZIPCode to character
non_matched_zips <- non_matched_zips %>%
  mutate(Property_ZipCode = as.character(Property_ZipCode))

count_non_local_apps <- left_join(zips_chi_join, non_matched_zips, by = c("ZCTA5CE10" = "Property_ZipCode"))

count_non_local_apps <- count_non_local_apps %>%
  mutate(outside_app_count = replace_na(outside_app_count, 0))

tm_shape(count_non_local_apps) +
  tm_polygons(fill = "outside_app_count", 
              fill.scale = tm_scale_intervals(n = 5, style = "jenks", values = "brewer.blues")) +
  tm_layout(legend.outside = TRUE, frame = FALSE) +
  tm_title("Count of Applications from outside property ZIP Code")


```

